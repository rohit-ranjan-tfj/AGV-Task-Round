{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "expected-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.feature_extraction import image\n",
    "from sklearn.cluster import spectral_clustering\n",
    "from moviepy.editor import VideoFileClip\n",
    "import tqdm\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adjusted-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(image,name):\n",
    "    name=\"\"+str(name)+\".png\"\n",
    "    cv2.imwrite(name,image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "completed-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayen(image):\n",
    "    grayenn = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    return grayenn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vital-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def darken(image):\n",
    "    new_image=np.zeros_like(image)\n",
    "    alpha=0.19\n",
    "    beta=-35\n",
    "    new_image=np.clip(np.multiply(alpha,image)+beta,0,255)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "instrumental-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective(image):\n",
    "    h,w=image.shape\n",
    "    pts1 = np.float32([[h/3,0],[h/3,w-1],[h-1,0],[h-1,w-1]])\n",
    "    pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "\n",
    "    dst = cv2.warpPerspective(median_image,M,(300,300))\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mexican-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_mask(image):\n",
    "    mask=np.zeros_like(image)\n",
    "    height,width = image.shape\n",
    "    a3 = np.array( [[[0,200],[1500,200],[width-1,800],[width-1,height-1],[0,height-1]]], dtype=np.int32 )\n",
    "    cv2.fillPoly(mask,a3,255)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "composed-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_pixels(image):\n",
    "    pix=[]\n",
    "    for x in range(image.shape[1]):\n",
    "        for y in range(image.shape[0]):\n",
    "            if(image[y,x]!=0):\n",
    "                pix.append((x,y))\n",
    "    return pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "complicated-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(rect1x):\n",
    "    he=rect1x.shape[0]\n",
    "    wi=rect1x.shape[1]\n",
    "    sum1x=0\n",
    "    sum1y=0\n",
    "    for i in range(he):\n",
    "        for j in range(wi):\n",
    "            sum1x=sum1x+j*rect1x[i,j]*(1/255)\n",
    "            sum1y=sum1y+i*rect1x[i,j]*(1/255)\n",
    "    sum1x=int(sum1x/window_w)\n",
    "    sum1y=int(sum1y/window_h)\n",
    "    return [sum1x,sum1y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "imposed-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yellow_black(image):\n",
    "    hsv=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "    yellow_lo=np.array([25,175,175])\n",
    "    yellow_hi=np.array([35,255,255])\n",
    "\n",
    "    mask=cv2.inRange(hsv,yellow_lo,yellow_hi)\n",
    "    \n",
    "    img=np.copy(image)\n",
    "    img[mask>0]=(0,0,0)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "incident-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def green_white(image):\n",
    "    hsv=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "    green_lo=np.array([20,10,30])\n",
    "    green_hi=np.array([80,255,255])\n",
    "\n",
    "    mask=cv2.inRange(hsv,green_lo,green_hi)\n",
    "    img=np.copy(image)\n",
    "    img[mask>0]=(255,255,255)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "improving-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(image):\n",
    "    img=np.zeros_like(image)\n",
    "    img=np.where(image!=(255,255,255),0,255)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "resistant-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brighten(image):\n",
    "    new_image=np.zeros_like(image)\n",
    "    gamma=2\n",
    "    new_image=np.clip(np.multiply(np.power(np.multiply(1/255,image),gamma),255),0,255)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "naked-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colour_threshing(image):\n",
    "    image = np.where(image <150, 0, 255)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "vital-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_white(image):\n",
    "    hsv=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "    white_lo=np.array([0,0,168])\n",
    "    white_hi=np.array([86,75,255])\n",
    "\n",
    "    mask=cv2.inRange(hsv,white_lo,white_hi)\n",
    "    img=np.copy(image)\n",
    "    img[mask>0]=(255,255,255)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "indirect-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve(x,a,b,c):\n",
    "    return a*(x**2)+b*x+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "mobile-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vid_pipeline(img):\n",
    "    x=0\n",
    "    y=0\n",
    "    width= img.shape[1]\n",
    "    height=img.shape[0]\n",
    "    crop_image = img[y:y+(int)(height*(5/6)), x:x+width]\n",
    "    width= crop_image.shape[1]\n",
    "    height=crop_image.shape[0]\n",
    "    \n",
    "    yellow=yellow_black(cv2.medianBlur(crop_image.astype(np.uint8),3))\n",
    "    green=green_white(yellow)\n",
    "    masked=binary(green)\n",
    "    masked = cv2.medianBlur(masked.astype(np.uint8),25)\n",
    "#     \n",
    "    crop_image=np.where(masked==(0,0,0),crop_image*0,crop_image*1)\n",
    "    whitened = white_white(cv2.medianBlur(crop_image.astype(np.uint8),15))\n",
    "    gray=binary(whitened)[:,:,0]\n",
    "    mask=roi_mask(np.uint8(gray))\n",
    "    combo=cv2.bitwise_and(mask,np.uint8(gray))  \n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    combo=cv2.dilate(np.uint8(combo.astype(np.float32)),kernel,iterations = 1)\n",
    "    \n",
    "    small=cv2.resize(combo,(96,45))\n",
    "    pixels=white_pixels(small)\n",
    "    set0=[]\n",
    "    set1=[]\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    ret,label,center2=cv2.kmeans(np.float32(pixels),2,None,criteria,10,cv2.KMEANS_PP_CENTERS)\n",
    "    for i in range(len(label)):\n",
    "        if(label[i]==0):\n",
    "            set0.append(pixels[i])\n",
    "        else:\n",
    "            set1.append(pixels[i])\n",
    "    curve1= curve_fit(curve,set1[:][0],set1[:][1])\n",
    "#     edges = cv2.Canny(np.uint8(combo),175,200)\n",
    "#     lines = cv2.HoughLines(edges,1,5*np.pi/180,50)\n",
    "    \n",
    "#     if (lines is None) or (len(lines)<2) :\n",
    "#         return crop_image\n",
    "    \n",
    "#     criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "#     ret,label,center2=cv2.kmeans(lines.astype(np.float32),2,None,criteria,10,cv2.KMEANS_PP_CENTERS)\n",
    "#     line_img=np.zeros_like(edges)\n",
    "#     for i in range(len(center2)):\n",
    "#         rho,theta = center2[i]\n",
    "#         a = np.cos(theta)\n",
    "#         b = np.sin(theta)\n",
    "#         x0 = a*rho\n",
    "#         y0 = b*rho\n",
    "#         x1 = int(x0 + 2000*(-b))\n",
    "#         y1 = int(y0 + 2000*(a))\n",
    "#         x2 = int(x0 - 2000*(-b))\n",
    "#         y2 = int(y0 - 2000*(a))\n",
    "#         cv2.line(line_img,(x1,y1),(x2,y2),255,30)\n",
    "#     line_img=cv2.bitwise_and(mask,line_img)    \n",
    "#     line_img=cv2.cvtColor(line_img,cv2.COLOR_GRAY2RGB)\n",
    "   \n",
    "# #     crop_image=np.where(masked==(0,0,0),crop_image*0,crop_image*1)\n",
    "#     crop_image=np.where(line_img==(255,255,255),(255,153,51),crop_image*1)\n",
    "       \n",
    "#     brighten_image=brighten(gray)\n",
    "#     bw_image=colour_threshing(cv2.medianBlur(brighten_image.astype(np.uint8),25))\n",
    "#     median_image = cv2.medianBlur(np.uint8(bw_image.astype(np.float32)),15)\n",
    "#     mask=roi_mask(median_image)\n",
    "#     combo=cv2.bitwise_and(mask,median_image)\n",
    "#     # save(combo,\"f3\")\n",
    "#     kernel = np.ones((5,5),np.uint8)\n",
    "#     dilation = cv2.dilate(np.uint8(combo.astype(np.float32)),kernel,iterations = 1)\n",
    "#     median_image = cv2.medianBlur(np.uint8(dilation.astype(np.float32)),35)\n",
    "#     dilation = cv2.dilate(np.uint8(median_image.astype(np.float32)),kernel,iterations = 5)\n",
    "#     rgb2=cv2.cvtColor(dilation,cv2.COLOR_GRAY2RGB)\n",
    "#     crop_image=np.where(rgb2==(255,255,255),crop_image*0,crop_image)\n",
    "\n",
    "   \n",
    "\n",
    "      \n",
    "#     return crop_image\n",
    "    return small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "indonesian-webcam",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Improper input: N=3 must not exceed M=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-0fba94a8d8e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"frame2.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"000\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-7c26e21983ac>\u001b[0m in \u001b[0;36mvid_pipeline\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mcurve1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcurve_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurve\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m#     edges = cv2.Canny(np.uint8(combo),175,200)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#     lines = cv2.HoughLines(edges,1,5*np.pi/180,50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/scipy/optimize/minpack.py\u001b[0m in \u001b[0;36mcurve_fit\u001b[0;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;31m# Remove full_output from kwargs, otherwise we're passing it in twice.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0mreturn_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'full_output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleastsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0mpopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfodict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mysize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfodict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fvec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/scipy/optimize/minpack.py\u001b[0m in \u001b[0;36mleastsq\u001b[0;34m(func, x0, args, Dfun, full_output, col_deriv, ftol, xtol, gtol, maxfev, epsfcn, factor, diag)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Improper input: N=%s must not exceed M=%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepsfcn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Improper input: N=3 must not exceed M=2"
     ]
    }
   ],
   "source": [
    "save(vid_pipeline(cv2.imread(\"frame2.png\")),\"000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vid_pipeline(img):\n",
    "#     x=0\n",
    "#     y=0\n",
    "#     width= img.shape[1]\n",
    "#     height=img.shape[0]\n",
    "#     crop_image = img[y:y+(int)(height*(5/6)), x:x+width]\n",
    "\n",
    "#     width= crop_image.shape[1]\n",
    "#     height=crop_image.shape[0]\n",
    "    \n",
    "#     yellow=yellow_black(crop_image)\n",
    "#     green=green_white(yellow)\n",
    "#     masked=binary(green)\n",
    "#     masked = cv2.medianBlur(masked.astype(np.uint8),9)\n",
    "    \n",
    "#     crop_image2=np.copy(crop_image)\n",
    "#     crop_image2 = cv2.medianBlur(np.uint8(crop_image2.astype(np.float32)),25)\n",
    "    \n",
    "#     median = cv2.medianBlur(np.uint8(crop_image2),35)\n",
    "    \n",
    "#     edge=cv2.Canny(np.uint8(median),10,100)\n",
    "    \n",
    "#     dilation = cv2.dilate(np.uint8(edge),np.ones((5,5)),iterations = 1)\n",
    "    \n",
    "# #     contours, hierarchy = cv2.findContours((np.uint8(dilation)), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# #     con=cv2.drawContours((np.uint8(edge)), contours, -1,255, 5)\n",
    "    \n",
    "    \n",
    "#     rgb=cv2.cvtColor(dilation,cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "#     crop_image=np.where(rgb==(255,255,255),crop_image*0,crop_image)\n",
    "    \n",
    "    \n",
    "# #     \n",
    "# # \n",
    "#     gray=grayen(crop_image2)\n",
    "#     brighten_image=brighten(gray)\n",
    "#     bw_image=colour_threshing(brighten_image)\n",
    "#     median_image = cv2.medianBlur(np.uint8(bw_image.astype(np.float32)),15)\n",
    "#     mask=roi_mask(median_image)\n",
    "#     combo=cv2.bitwise_and(mask,median_image)\n",
    "#     # save(combo,\"f3\")\n",
    "#     kernel = np.ones((5,5),np.uint8)\n",
    "#     dilation = cv2.dilate(np.uint8(combo.astype(np.float32)),kernel,iterations = 1)\n",
    "#     median_image = cv2.medianBlur(np.uint8(dilation.astype(np.float32)),35)\n",
    "#     dilation = cv2.dilate(np.uint8(median_image.astype(np.float32)),kernel,iterations = 3)\n",
    "#     rgb2=cv2.cvtColor(dilation,cv2.COLOR_GRAY2RGB)\n",
    "#     crop_image=np.where(rgb2==(255,255,255),crop_image*0,crop_image)\n",
    "\n",
    "   \n",
    "#     crop_image=np.where(masked==(0,0,0),crop_image*0,crop_image*1)\n",
    "      \n",
    "#     return crop_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myclip = VideoFileClip('sample_input.mp4')\n",
    "# output_vid = 'output4newattempt.mp4'\n",
    "# clip = myclip.fl_image(vid_pipeline)\n",
    "# clip.write_videofile(output_vid, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cap= cv2.VideoCapture('sample_input.mp4')\n",
    "# i=0\n",
    "# while(cap.isOpened()):\n",
    "#     i+=1\n",
    "#     ret, frame = cap.read()\n",
    "#     if(i%10 != 0):\n",
    "#         continue\n",
    "#     if ret == False:\n",
    "#         break\n",
    "#     cv2.imwrite('f'+str(i)+'.jpg',vid_pipeline(frame))\n",
    "#     print(\"-\",i,\"/3598\")\n",
    "    \n",
    " \n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import glob\n",
    " \n",
    "# img_array = []\n",
    "# for filename in glob.glob('C:/New folder/Images/*.jpg'):\n",
    "#     img = cv2.imread(filename)\n",
    "#     height, width, layers = img.shape\n",
    "#     size = (width,height)\n",
    "#     img_array.append(img)\n",
    " \n",
    " \n",
    "# out = cv2.VideoWriter('project.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    " \n",
    "# for i in range(len(img_array)):\n",
    "#     out.write(img_array[i])\n",
    "# out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
